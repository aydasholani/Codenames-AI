{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import librarys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check torch version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Antal CPU-kärnor:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Ultralytics settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDict(\"C:\\Users\\shool\\AppData\\Roaming\\Ultralytics\\settings.json\"):\n",
      "{\n",
      "  \"settings_version\": \"0.0.6\",\n",
      "  \"datasets_dir\": \"C:\\\\Users\\\\shool\\\\Dev\\\\Codenames-Board\\\\modelv12\\\\datasets\",\n",
      "  \"weights_dir\": \"weights\",\n",
      "  \"runs_dir\": \"runs\",\n",
      "  \"uuid\": \"0847b39e9ea20ed4a1701ad224a7b4090217127da71fb1cbe1040083b7cf976f\",\n",
      "  \"sync\": true,\n",
      "  \"api_key\": \"\",\n",
      "  \"openai_api_key\": \"\",\n",
      "  \"clearml\": true,\n",
      "  \"comet\": true,\n",
      "  \"dvc\": true,\n",
      "  \"hub\": true,\n",
      "  \"mlflow\": true,\n",
      "  \"neptune\": true,\n",
      "  \"raytune\": true,\n",
      "  \"tensorboard\": true,\n",
      "  \"wandb\": true,\n",
      "  \"vscode_msg\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# dotenv.load_dotenv()\n",
    "# settings.reset()\n",
    "\n",
    "# ROBOFLOW_API_KEY = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "# PROJECT_ID = os.getenv(\"PROJECT_OBJECT_DETECTION\")\n",
    "# VERSION = os.getenv(\"OBJECT_DETECTION_MODEL_VERSION\")\n",
    "\n",
    "# def download_dataset(PROJECT_ID, version, yolov):\n",
    "#   rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "#   project = rf.workspace().project(PROJECT_ID)\n",
    "# #   version = project.version(version)\n",
    "#   dataset = project.version(version).download(yolov)\n",
    "#   return dataset\n",
    "\n",
    "# dataset = download_dataset(PROJECT_ID, 9, yolov=\"yolov11\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.ultralytics.com/modes/train/#train-settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(data):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = YOLO(\"yolo11n.pt\")  # Laddar in förtränad modell\n",
    "    model.to(device)\n",
    "    results = model.train(\n",
    "        data=data, \n",
    "        epochs=100, \n",
    "        imgsz=640, \n",
    "        batch=8,\n",
    "        workers=os.cpu_count(),\n",
    "        exist_ok=True\n",
    "        )\n",
    "    return results\n",
    "\n",
    "results = model_training(data=\"modelv12.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.21  Python-3.11.10 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\shool\\Dev\\Codenames-Board\\modelv12\\datasets\\labels\\val.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:14<00:00, 14.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         12        134          1          1      0.995      0.929\n",
      "               class_0         12         69          1          1      0.995      0.979\n",
      "               class_1         12         65          1          1      0.995      0.879\n",
      "Speed: 2.7ms preprocess, 19.9ms inference, 0.0ms loss, 10.1ms postprocess per image\n",
      "Saving runs\\detect\\val\\predictions.json...\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
      "0.9294441006932447\n",
      "0.995\n",
      "0.995\n",
      "[     0.9795     0.87939]\n"
     ]
    }
   ],
   "source": [
    "def model_validation():\n",
    "    model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "    metrics = model.val(\n",
    "        data=\"modelv12.yaml\", \n",
    "        imgsz=640, \n",
    "        batch=16, \n",
    "        conf=0.8, \n",
    "        iou=0.6, \n",
    "        device=\"0\",\n",
    "        dnn=True,\n",
    "        exist_ok=True,\n",
    "        save_json=True)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "metrics = model_validation()\n",
    "print(metrics.box.map)\n",
    "print(metrics.box.map50)\n",
    "print(metrics.box.map75)\n",
    "print(metrics.box.maps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja, detta är en slags utvärderingsrapport, men den skiljer sig från en klassisk \"classification report\" i termer av form och innehåll. I YOLO och andra objektidentifieringsmodeller rapporteras oftast precision, recall, mAP@0.5, och mAP@0.5:0.95 istället för den klassiska precision, recall och F1-score som används i en typisk klassificeringsrapport.\n",
    "\n",
    "Här är en snabb översikt av vad raderna betyder:\n",
    "\n",
    "- **Box(P):** Precision för objektidentifiering, som anger hur många av modellens positiva förutsägelser som var korrekta.\n",
    "- **R:** Recall, eller hur många av de verkliga objekten som modellen korrekt identifierade.\n",
    "- **mAP@0.5:** Mean Average Precision vid en tröskel på 0.5, vilket är ett mått på hur bra modellen är på att hitta och korrekt avgränsa objekten.\n",
    "- **mAP@0.5:0.95:** mAP beräknat över flera trösklar (från 0.5 till 0.95) för att ge en mer generell bild av modellens prestanda.\n",
    "Denna rapport är mer omfattande än en klassisk klassificeringsrapport och fokuserar på modellens prestanda för objektidentifiering snarare än ren klassificering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x640 25 class_0s, 25 class_1s, 21.7ms\n",
      "Speed: 4.5ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, conf=0.8):\n",
    "\n",
    "    model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "    \n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    results = model.predict(\n",
    "        img, \n",
    "        conf=conf, \n",
    "        stream=True,\n",
    "        save=True\n",
    "    )\n",
    "    \n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = [int(coord.item()) for coord in box.xyxy[0]]\n",
    "            label = int(box.cls.item())\n",
    "            confidence = box.conf.item()\n",
    "            \n",
    "            # Rita bounding boxen på bilden\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, f\"Label: {label}, Conf: {confidence:.2f}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "test_image = os.path.join(os.getcwd(), \"test\", \"board_018.png\")\n",
    "\n",
    "predict_image(test_image)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
